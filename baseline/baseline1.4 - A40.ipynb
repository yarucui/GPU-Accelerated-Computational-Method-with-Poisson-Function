{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8b03166-1508-4dbb-8d93-5a4897bb9126",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 是否可用: True\n",
      "当前 GPU: NVIDIA A40\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"GPU 是否可用: {torch.cuda.is_available()}\")\n",
    "print(f\"当前 GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0731caa3-2a44-4a2a-bc45-6bef64e32a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在构建 1000x1000 的系数矩阵...\n",
      "矩阵构建完成，耗时: 4.29 秒\n",
      "单次 SpMV 耗时: 0.00590 秒\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "# 设置网格大小 (根据 PPT 第3页的示例)\n",
    "N, M = 1000, 1000 \n",
    "num_nodes = N * M\n",
    "\n",
    "# 确保在 A40 GPU 上运行\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def build_poisson_sparse_matrix(N, M):\n",
    "    print(f\"正在构建 {N}x{M} 的系数矩阵...\")\n",
    "    indices = []\n",
    "    values = []\n",
    "\n",
    "    for i in range(N):\n",
    "        for j in range(M):\n",
    "            row = i * M + j\n",
    "            \n",
    "            # 中心点 (Diagonal): 系数为 4\n",
    "            indices.append([row, row])\n",
    "            values.append(4.0)\n",
    "            \n",
    "            # 5点模板的邻居点 (系数为 -1)\n",
    "            for di, dj in [(-1, 0), (1, 0), (0, -1), (0, 1)]:\n",
    "                ni, nj = i + di, j + dj\n",
    "                if 0 <= ni < N and 0 <= nj < M:\n",
    "                    col = ni * M + nj\n",
    "                    indices.append([row, col])\n",
    "                    values.append(-1.0)\n",
    "\n",
    "    # 转换为 PyTorch 稀疏张量 (COO 格式)\n",
    "    i_ts = torch.LongTensor(indices).t()\n",
    "    v_ts = torch.FloatTensor(values)\n",
    "    A = torch.sparse_coo_tensor(i_ts, v_ts, (num_nodes, num_nodes)).to(device)\n",
    "    return A\n",
    "\n",
    "# 1. 运行基准测试\n",
    "start_time = time.time()\n",
    "A_sparse = build_poisson_sparse_matrix(N, M)\n",
    "print(f\"矩阵构建完成，耗时: {time.time() - start_time:.2f} 秒\")\n",
    "\n",
    "# 2. 创建随机源项 b 和初始解 x\n",
    "b = torch.randn(num_nodes, 1).to(device)\n",
    "x = torch.zeros(num_nodes, 1).to(device)\n",
    "\n",
    "# 3. 测试一次矩阵-向量乘法 (SpMV)\n",
    "start_time = time.time()\n",
    "r = torch.sparse.mm(A_sparse, x) - b\n",
    "print(f\"单次 SpMV 耗时: {time.time() - start_time:.5f} 秒\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3736c8bf-b840-4f8b-8ef8-361c8dfc638f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始 1000x1000 网格的基准测试...\n",
      "[cuda] 迭代次数: 10/100\n",
      "[cuda] 迭代次数: 20/100\n",
      "[cuda] 迭代次数: 30/100\n",
      "[cuda] 迭代次数: 40/100\n",
      "[cuda] 迭代次数: 50/100\n",
      "[cuda] 迭代次数: 60/100\n",
      "[cuda] 迭代次数: 70/100\n",
      "[cuda] 迭代次数: 80/100\n",
      "[cuda] 迭代次数: 90/100\n",
      "[cuda] 迭代次数: 100/100\n",
      "--- GPU (A40) 总耗时: 0.8605 秒 ---\n",
      "[cpu] 迭代次数: 10/100\n",
      "[cpu] 迭代次数: 20/100\n",
      "[cpu] 迭代次数: 30/100\n",
      "[cpu] 迭代次数: 40/100\n",
      "[cpu] 迭代次数: 50/100\n",
      "[cpu] 迭代次数: 60/100\n",
      "[cpu] 迭代次数: 70/100\n",
      "[cpu] 迭代次数: 80/100\n",
      "[cpu] 迭代次数: 90/100\n",
      "[cpu] 迭代次数: 100/100\n",
      "--- CPU 总耗时: 13.6922 秒 ---\n",
      "\n",
      "加速比 (Speedup): 15.91x\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "def run_jacobi_benchmark(N, M, iterations=100, device_type=\"cuda\"):\n",
    "    device = torch.device(device_type)\n",
    "    num_nodes = N * M\n",
    "    \n",
    "    # 1. 准备数据\n",
    "    # A_sparse 已经在你之前的单元格中构建好，这里假设它叫 A\n",
    "    # 注意：Jacobi 迭代通常需要矩阵的对角线元素 D 和剩余部分 R\n",
    "    # 在 5 点差分中，对角线 D 全是 4.0\n",
    "    b = torch.ones((num_nodes, 1), device=device)\n",
    "    x = torch.zeros((num_nodes, 1), device=device)\n",
    "    D_inv = 1.0 / 4.0  # 泊松方程对角线逆\n",
    "    \n",
    "    # 构造迭代中的 A_off_diagonal (A - D)\n",
    "    # 为了简化测试，我们直接用 A * x 并在迭代中处理\n",
    "    \n",
    "    torch.cuda.synchronize() if device_type == \"cuda\" else None\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        # Jacobi 公式: x^(k+1) = D^-1 * (b - R * x^k)\n",
    "        # 其中 R*x = A*x - D*x = A*x - 4*x\n",
    "        Ax = torch.sparse.mm(A_sparse.to(device), x)\n",
    "        x = x + D_inv * (b - Ax)\n",
    "        \n",
    "        # 模拟每 10 次迭代打印一次进度，方便你在 Grafana 看到波动\n",
    "        if (i+1) % 10 == 0:\n",
    "            print(f\"[{device_type}] 迭代次数: {i+1}/{iterations}\")\n",
    "\n",
    "    torch.cuda.synchronize() if device_type == \"cuda\" else None\n",
    "    end_time = time.time()\n",
    "    \n",
    "    return end_time - start_time\n",
    "\n",
    "# 执行对比测试\n",
    "grid_size = 1000 # 对应 PPT 第3页\n",
    "iters = 100\n",
    "\n",
    "print(f\"开始 {grid_size}x{grid_size} 网格的基准测试...\")\n",
    "\n",
    "# GPU 测试\n",
    "gpu_time = run_jacobi_benchmark(grid_size, grid_size, iterations=iters, device_type=\"cuda\")\n",
    "print(f\"--- GPU (A40) 总耗时: {gpu_time:.4f} 秒 ---\")\n",
    "\n",
    "# CPU 测试 (警告：可能会比 GPU 慢很多)\n",
    "cpu_time = run_jacobi_benchmark(grid_size, grid_size, iterations=iters, device_type=\"cpu\")\n",
    "print(f\"--- CPU 总耗时: {cpu_time:.4f} 秒 ---\")\n",
    "\n",
    "print(f\"\\n加速比 (Speedup): {cpu_time / gpu_time:.2f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c73209c8-b860-4fb5-bb7c-08d2afba36e8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始集成基准测试 (使用设备: NVIDIA A40)...\n",
      "\n",
      ">>> 正在测试网格: 500x500 (总节点数: 0.2 Million)\n",
      "GPU (A40) 耗时: 0.2158 秒\n",
      "CPU 耗时: 2.8938 秒 | 加速比: 13.41x\n",
      "\n",
      ">>> 正在测试网格: 1000x1000 (总节点数: 1.0 Million)\n",
      "GPU (A40) 耗时: 0.8607 秒\n",
      "CPU 耗时: 11.4994 秒 | 加速比: 13.36x\n",
      "\n",
      ">>> 正在测试网格: 1500x1500 (总节点数: 2.2 Million)\n",
      "GPU (A40) 耗时: 1.9799 秒\n",
      "CPU 耗时: 25.8712 秒 | 加速比: 13.07x\n",
      "\n",
      ">>> 正在测试网格: 2000x2000 (总节点数: 4.0 Million)\n",
      "GPU (A40) 耗时: 3.6191 秒\n",
      "CPU 耗时: 45.9797 秒 | 加速比: 12.70x\n",
      "\n",
      "实验完成。请记录上述数据用于 Week 4 的报告编写。\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# ==========================================\n",
    "# 1. 核心功能函数定义\n",
    "# ==========================================\n",
    "\n",
    "def build_poisson_sparse_matrix(N, M, device):\n",
    "    \"\"\"\n",
    "    构建 2D 泊松方程的 5 点差分系数矩阵 (COO 格式) [cite: 638, 657]\n",
    "    \"\"\"\n",
    "    num_nodes = N * M\n",
    "    indices = []\n",
    "    values = []\n",
    "\n",
    "    # 遍历网格构建 5 点模板 [cite: 696]\n",
    "    for i in range(N):\n",
    "        for j in range(M):\n",
    "            row = i * M + j\n",
    "            # 中心点 (Diagonal): 系数为 4\n",
    "            indices.append([row, row])\n",
    "            values.append(4.0)\n",
    "            \n",
    "            # 上下左右邻居 (Off-diagonal): 系数为 -1\n",
    "            for di, dj in [(-1, 0), (1, 0), (0, -1), (0, 1)]:\n",
    "                ni, nj = i + di, j + dj\n",
    "                if 0 <= ni < N and 0 <= nj < M:\n",
    "                    col = ni * M + nj\n",
    "                    indices.append([row, col])\n",
    "                    values.append(-1.0)\n",
    "\n",
    "    # 转换为 PyTorch 稀疏张量 [cite: 654]\n",
    "    i_ts = torch.LongTensor(indices).t()\n",
    "    v_ts = torch.FloatTensor(values)\n",
    "    # 将矩阵直接放置在目标设备上 \n",
    "    A = torch.sparse_coo_tensor(i_ts, v_ts, (num_nodes, num_nodes)).to(device)\n",
    "    return A\n",
    "\n",
    "def run_jacobi_benchmark(A_sparse, N, M, iterations=100, device_type=\"cuda\"):\n",
    "    \"\"\"\n",
    "    执行 Jacobi 迭代基准测试 [cite: 663, 751]\n",
    "    \"\"\"\n",
    "    device = torch.device(device_type)\n",
    "    num_nodes = N * M\n",
    "    \n",
    "    # 准备向量数据\n",
    "    b = torch.ones((num_nodes, 1), device=device)\n",
    "    x = torch.zeros((num_nodes, 1), device=device)\n",
    "    D_inv = 0.25  # 对于泊松 5 点模板，对角线元素的逆为 1/4\n",
    "    \n",
    "    # 同步并开始计时 (确保 GPU 计时准确) \n",
    "    if device_type == \"cuda\":\n",
    "        torch.cuda.synchronize()\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        # 核心操作：矩阵-向量乘法 (SpMV) [cite: 661]\n",
    "        # Jacobi 公式简化版: x_new = x_old + D_inv * (b - A * x_old)\n",
    "        Ax = torch.sparse.mm(A_sparse, x)\n",
    "        x = x + D_inv * (b - Ax)\n",
    "\n",
    "    if device_type == \"cuda\":\n",
    "        torch.cuda.synchronize()\n",
    "        \n",
    "    return time.time() - start_time\n",
    "\n",
    "# ==========================================\n",
    "# 2. 自动化实验逻辑 (Scaling Test)\n",
    "# ==========================================\n",
    "\n",
    "# 实验配置 \n",
    "grid_sizes = [500, 1000, 1500, 2000] # 测试从 500^2 到 2000^2 的规模\n",
    "iters = 100  # 每次测试迭代 100 次\n",
    "gpu_results = []\n",
    "cpu_results = []\n",
    "\n",
    "print(f\"开始集成基准测试 (使用设备: NVIDIA A40)...\")\n",
    "\n",
    "for n in grid_sizes:\n",
    "    print(f\"\\n>>> 正在测试网格: {n}x{n} (总节点数: {n*n/1e6:.1f} Million)\")\n",
    "    \n",
    "    # GPU 测试\n",
    "    gpu_device = torch.device(\"cuda\")\n",
    "    A_gpu = build_poisson_sparse_matrix(n, n, gpu_device)\n",
    "    t_gpu = run_jacobi_benchmark(A_gpu, n, n, iterations=iters, device_type=\"cuda\")\n",
    "    gpu_results.append(t_gpu)\n",
    "    print(f\"GPU (A40) 耗时: {t_gpu:.4f} 秒\")\n",
    "    \n",
    "    # CPU 测试 (因 CPU 较慢，超过 1500 规模建议跳过或减少次数)\n",
    "    #if n <= 1000:\n",
    "    cpu_device = torch.device(\"cpu\")\n",
    "    A_cpu = build_poisson_sparse_matrix(n, n, cpu_device)\n",
    "    t_cpu = run_jacobi_benchmark(A_cpu, n, n, iterations=iters, device_type=\"cpu\")\n",
    "    cpu_results.append(t_cpu)\n",
    "    print(f\"CPU 耗时: {t_cpu:.4f} 秒 | 加速比: {t_cpu/t_gpu:.2f}x\")\n",
    "    #else:\n",
    "        #print(\"规模较大，跳过 CPU 基准测试以节省资源。\")\n",
    "        #cpu_results.append(None)\n",
    "\n",
    "# ==========================================\n",
    "# 3. 结果可视化 (Visualization)\n",
    "# ==========================================\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(grid_sizes, gpu_results, 'o-', linewidth=2, label='PyTorch GPU (A40)')\n",
    "# 过滤掉为 None 的 CPU 数据进行绘图\n",
    "valid_cpu_idx = [i for i, v in enumerate(cpu_results) if v is not None]\n",
    "if valid_cpu_idx:\n",
    "    plt.plot([grid_sizes[i] for i in valid_cpu_idx], \n",
    "             [cpu_results[i] for i in valid_cpu_idx], \n",
    "             's--', linewidth=2, label='PyTorch CPU')\n",
    "\n",
    "plt.title('Poisson Solver Performance Scaling (Grid size vs Time) [cite: 664]')\n",
    "plt.xlabel('Grid Side Dimension (N)')\n",
    "plt.ylabel(f'Execution Time for {iters} Iterations (s)')\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.yscale('log') # 建议使用对数坐标以便观察巨大的性能差距\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n实验完成。请记录上述数据用于 Week 4 的报告编写。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7a53fe-d2c3-4863-9a5a-96c72782a06d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
